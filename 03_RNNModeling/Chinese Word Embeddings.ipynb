{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\users\\usz0b3l\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Windows'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import string\n",
    "# import fasttext\n",
    "import platform\n",
    "platform.system()\n",
    "# import tensorflow as tf\n",
    "# sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwe = np.load(\"zh.bin.syn0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50101, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwe_neg = np.load(\"zh.bin.syn1neg.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50101, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwe_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Matrix Lookup (cross platform)\n",
    "Reference: [https://github.com/facebookresearch/fastText/tree/master/python](https://github.com/facebookresearch/fastText/tree/master/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    with open(\"zh/wiki.zh.vec\", \"r\", encoding='utf-8') as fin:\n",
    "        words = fin.readlines()\n",
    "elif platform.system() == 'Darwin':  # Mac OSX\n",
    "    with open(\"zh/wiki.zh.vec\", \"r\") as fin:\n",
    "        words = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332648"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    wiki_vocab = [x.split(' ')[0] for x in words[1:]]\n",
    "elif platform.system() == 'Darwin':\n",
    "    wiki_vocab = [x.split(' ')[0].decode('utf-8') for x in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332647"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本\n"
     ]
    }
   ],
   "source": [
    "print(wiki_vocab[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wiki_embeddings = np.array([x.strip().split(' ')[1:] for x in words[1:]])  # will probably run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(file_path):\n",
    "    if platform.system() == 'Windows':\n",
    "        with open(file_path, 'r', encoding='utf-8') as fin:\n",
    "            vocab = [x.strip() for x in fin.readlines()]\n",
    "            vocab = [x for x in vocab if x != '']\n",
    "    elif platform.system() == 'Darwin':\n",
    "        with open(file_path, 'r') as fin:\n",
    "            vocab = [x.strip() for x in fin.readlines()]\n",
    "            vocab = [x.decode('utf-8') for x in vocab if x != '']\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = read_vocab('../01_WebScraping/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沉静\n"
     ]
    }
   ],
   "source": [
    "print(vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return [token for token in jieba.cut(text) if token not in string.punctuation+\" \" and token != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lyrics(file_path):\n",
    "    if platform.system() == 'Windows':\n",
    "        lyrics = [line.strip() for line in open(file_path, 'r', encoding='utf-8').readlines()]\n",
    "        lyrics = [custom_tokenizer(text) for text in lyrics]\n",
    "    elif platform.system() == 'Darwin':\n",
    "        lyrics = [line.strip() for line in open(file_path, 'r').readlines()]\n",
    "        lyrics = [custom_tokenizer(text) for text in lyrics]\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\users\\usz0b3l\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.937 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "lyrics = read_lyrics('../01_WebScraping/lyrics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "210\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "for item in lyrics[:3]:\n",
    "    print(len(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_lookup(token, vocab, word_embedding):\n",
    "    try:\n",
    "        return [float(x) for x in word_embedding[vocab.index(token)+1].strip().split(' ')[1:]]\n",
    "    except ValueError:\n",
    "        print('Token not in vocabulary!')\n",
    "        # See https://github.com/facebookresearch/fastText#obtaining-word-vectors-for-out-of-vocabulary-words for more details\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_lookup(vocab[5], wiki_vocab, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "fastText: Cannot load zh/wiki.zh.bin due to C++ extension failed to allocate the memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32mfasttext\\fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.load_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: vector<T> too long",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8fc38d27d987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Skipgram model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zh/wiki.zh.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'king'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get the vector of the word 'king'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfasttext\\fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.load_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: fastText: Cannot load zh/wiki.zh.bin due to C++ extension failed to allocate the memory"
     ]
    }
   ],
   "source": [
    "# Skipgram model\n",
    "model = fasttext.load_model('zh/wiki.zh.bin')\n",
    "print(model['king'])  # get the vector of the word 'king'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
